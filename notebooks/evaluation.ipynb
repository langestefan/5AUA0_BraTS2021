{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import gzip\n",
    "import os\n",
    "import cv2\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# for relative imports to work in notebooks\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from model.model  import BraTS2021BaseUnetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model\n",
    "# best model is located at: python test.py -r saved/models/BraTS2021_Base_Unet/0523_152701/model_best.pth\n",
    "# model = load_model(path = '../saved/models/BraTS2021_Base_Unet/0523_152701/model_best.pth')\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# # create network object from saved\\models\\BraTS2021_Base_Unet\\0523_152701\n",
    "# config = ConfigParser.from_args(args)\n",
    "# model = config.init_obj('arch', module_arch)\n",
    "\n",
    "# # unet_model = BraTS2021BaseUnetModel()\n",
    "\n",
    "# # execute from pre-trained model\n",
    "# # unet_model.load_state_dict(torch.load('../model/unet_1epoch.pth'))\n",
    "\n",
    "# # checkpoint = torch.load('../model/unet_1epoch.pth')\n",
    "# # state_dict = checkpoint['state_dict']\n",
    "# # unet_model = torch.nn.DataParallel(unet_model)\n",
    "# # unet_model.load_state_dict(state_dict)\n",
    "\n",
    "# print(unet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dice coefficient for class total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dice_coeff_enhancing_tumor(output, target):\n",
    "    \"\"\" Dice coeffecient for enhancing tumor(class 3)\n",
    "        See: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook#Dice-Loss\n",
    "    Args:\n",
    "        output (torch.Tensor): model output probalities between [0-1], shape (N, C, H, W)\n",
    "        target (torch.Tensor): target one-hot encoded, shape (N, C, H, W)\n",
    "        eps (int): prevent division by 0\n",
    "    Returns:\n",
    "        torch.Tensor: dice coeff. Shape: (1,)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # take tumor class 3\n",
    "        target = target[:, [3]]\n",
    "        output = output[:, [3]]\n",
    "\n",
    "        dice_coeff_en = dice_coeff(output, target, include_background=False)\n",
    "    return dice_coeff_en\n",
    "\n",
    "\n",
    "def dice_coeff_tumor_core(output, target):\n",
    "    \"\"\" Dice coeffecient for tumor core (union of classes 1+3)\n",
    "        See: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook#Dice-Loss\n",
    "    Args:\n",
    "        output (torch.Tensor): model output probalities between [0-1], shape (N, C, H, W)\n",
    "        target (torch.Tensor): target one-hot encoded, shape (N, C, H, W)\n",
    "        eps (int): prevent division by 0\n",
    "    Returns:\n",
    "        torch.Tensor: dice coeff. Shape: (1,)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # take tumor classes 1 and 3\n",
    "        target = target[:, [1, 3]]\n",
    "        output = output[:, [1, 3]]\n",
    "\n",
    "        dice_coeff_tc = dice_coeff(output, target, include_background=False)\n",
    "    return dice_coeff_tc\n",
    "\n",
    "\n",
    "\n",
    "def dice_coeff_healthy(output, target):\n",
    "    \"\"\" Dice coeffecient for background/healthy class (0)\n",
    "        See: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook#Dice-Loss\n",
    "    Args:\n",
    "        output (torch.Tensor): model output probalities between [0-1], shape (N, C, H, W)\n",
    "        target (torch.Tensor): target one-hot encoded, shape (N, C, H, W)\n",
    "        eps (int): prevent division by 0\n",
    "    Returns:\n",
    "        torch.Tensor: dice coeff. Shape: (1,)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # take only the background/healthy class (0)\n",
    "        target = target[:, :1]\n",
    "        output = output[:, :1]\n",
    "\n",
    "        dice_coef_healthy = dice_coeff(output, target)\n",
    "    return dice_coef_healthy\n",
    "\n",
    "\n",
    "def dice_coeff(output, target, reduce_class=True, reduce_batch=True, \n",
    "               eps=1e-7, smooth_nr=0, smooth_dr=0, include_background=True, backprop=False):\n",
    "    \"\"\" Dice coeffecient\n",
    "        See: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook#Dice-Loss  \n",
    "\n",
    "    Args:\n",
    "        output (torch.Tensor): model output probalities between [0-1], shape (N, C, H, W)\n",
    "        target (torch.Tensor): target one-hot encoded, shape (N, C, H, W)\n",
    "        reduce_class (bool): if True, sum over class dimension\n",
    "        reduce_batch (bool): if True, sum over batch dimension\n",
    "        eps (int): prevent division by 0\n",
    "        smooth_nr (float): smooth factor, numerator\n",
    "        smooth_dr (float): smooth factor, denominator\n",
    "        include_background (bool): if True, include background class\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: dice coeff. Shape: (1,) if reduce_class&reduce_batch; \n",
    "                                         (C,) if reduce_batch; \n",
    "                                         (N,) if reduce_class; \n",
    "                                         (N, C) otherwise (default) .requires_grad_(False)\n",
    "    \"\"\"\n",
    "    dim = [2, 3] \n",
    "\n",
    "    if reduce_class:\n",
    "        dim = [1] + dim\n",
    "\n",
    "    if reduce_batch:\n",
    "        dim = [0] + dim\n",
    "\n",
    "    if not include_background:\n",
    "        target = target[:, 1:]\n",
    "        output = output[:, 1:]\n",
    "\n",
    "    # contiguous() ensures that the memory is not reallocated during the operation\n",
    "    output = output.contiguous()\n",
    "    target = target.contiguous()   \n",
    "\n",
    "    if not backprop:\n",
    "        with torch.no_grad():\n",
    "            intersection = torch.sum(torch.mul(output, target), dim=dim)\n",
    "            abs_area = torch.sum(output, dim=dim) + torch.sum(target, dim=dim) + eps # abs_area = abs_output + abs_target\n",
    "\n",
    "            # dice = 2 * (A U B) / (|A| + |B|)\n",
    "            dice_coeff = (2. * intersection + smooth_nr) / (abs_area + smooth_dr)\n",
    "    \n",
    "    else:\n",
    "        intersection = torch.sum(torch.mul(output, target), dim=dim)\n",
    "        abs_area = torch.sum(output, dim=dim) + torch.sum(target, dim=dim) + eps # abs_area = abs_output + abs_target\n",
    "\n",
    "        # dice = 2 * (A U B) / (|A| + |B|)\n",
    "        dice_coeff = (2. * intersection + smooth_nr) / (abs_area + smooth_dr)        \n",
    "\n",
    "    return dice_coeff  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target.shape:  torch.Size([8, 4, 240, 240])\n",
      "output.shape:  torch.Size([8, 4, 240, 240])\n",
      "Target shape:  torch.Size([8, 2, 240, 240])\n",
      "dice_coef_wt:  tensor(0.5691)\n"
     ]
    }
   ],
   "source": [
    "# random data with shape (N, C, H, W) =  torch.Size([N, 4, 240, 240])\n",
    "C = 4\n",
    "N = 8\n",
    "H = 240\n",
    "W = 240\n",
    "\n",
    "output = torch.randint(0, 3, (N, C, H, W), dtype=torch.float32)\n",
    "output = F.softmax(output, dim=1)\n",
    "\n",
    "# target\n",
    "target = torch.randint(0, C, (N, H, W), dtype=torch.int64)\n",
    "target = F.one_hot(target, num_classes=C)\n",
    "target = torch.transpose(target, 1, 3)\n",
    "\n",
    "# test output\n",
    "test_output = torch.randint(0, C, (N, H, W), dtype=torch.int64)\n",
    "test_output = F.one_hot(test_output, num_classes=C)\n",
    "test_output = torch.transpose(test_output, 1, 3)\n",
    "\n",
    "print(\"target.shape: \", target.shape)\n",
    "print(\"output.shape: \", output.shape)\n",
    "\n",
    "# Semantics:\n",
    "#     Whole tumor: \t\tWT: \tUnion of all tumor labels (1) + (2) + (4)\n",
    "#     Tumor core: \t\tTC: \tGross tumor core outline --> Union of labels ET(4) + necrosis(1)\n",
    "#     Enhancing tumor: \tET: \tOnly ET(4)      \n",
    "\n",
    "def dice_coeff_whole_tumor(output, target):\n",
    "    \"\"\" Dice coeffecient for whole tumor (union of classes 1-3)\n",
    "        See: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook#Dice-Loss\n",
    "    Args:\n",
    "        output (torch.Tensor): model output probalities between [0-1], shape (N, C, H, W)\n",
    "        target (torch.Tensor): target one-hot encoded, shape (N, C, H, W)\n",
    "        eps (int): prevent division by 0\n",
    "    Returns:\n",
    "        torch.Tensor: dice coeff. Shape: (1,)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # take all the tumor classes\n",
    "        target = target[:, [1, 3]]\n",
    "        output = output[:, [1, 3]]\n",
    "        print(\"Target shape: \", target.shape)\n",
    "\n",
    "        target_union = torch.sum(target, dim=1).unsqueeze(1).clip(0, 1)\n",
    "        output_union = torch.argmax(output, dim=1).unsqueeze(1).clip(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        # dice_coeff_wt = dice_coeff(target_union, target_union, include_background=False, reduce_class=True)\n",
    "        dice_coeff_wt = dice_coeff(target_union, target_union, include_background=True, reduce_class=True)\n",
    "    return dice_coeff_wt\n",
    "\n",
    "dice_coef_wt = dice_coeff_whole_tumor(output, output)\n",
    "print(\"dice_coef_wt: \", dice_coef_wt)\n",
    "print(\"output mean: \", torch.mean(output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369441202de9f090a0e57b38848d3e186c8686d751df00b39c544f960532016f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
