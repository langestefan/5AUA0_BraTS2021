{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import gzip\n",
    "import os\n",
    "import cv2\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import sys\n",
    "\n",
    "# for relative imports to work in notebooks\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from model.model  import BraTS2021AttentionUnetModel_V4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select which BRaTS2021 case we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = '00349'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of model:  <class 'model.model.BraTS2021AttentionUnetModel_V4'>\n",
      "BraTS2021AttentionUnetModel_V4(\n",
      "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv1): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv2): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv3): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv4): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv5): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up5): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att5): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv5): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up4): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att4): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv4): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up3): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att3): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv3): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up2): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att2): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv2): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv_1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model is located at: \n",
    "# unet_base_model_path = '../saved/models/base_unet_dice/model_best.pth'\n",
    "# unet_base_aug_model_path = '../saved/models/base_unet_dice_aug_20_134/model_best.pth'\n",
    "# unet_base_aug_model_path = '../saved/models/BraTS2021_Base_Unet/0616_220253/model_best.pth'\n",
    "att_unet_v4_model_path = '../saved/models/attention_unet_dice_v4_all_aug_30_124/model_best.pth'\n",
    "\n",
    "model = att_unet_v4_model_path\n",
    "# load base unet model\n",
    "att_unet_v4_model = BraTS2021AttentionUnetModel_V4(plot_attention=True)\n",
    "checkpoint = torch.load(model)\n",
    "state_dict = checkpoint['state_dict']\n",
    "att_unet_v4_model.load_state_dict(state_dict)\n",
    "print(\"type of model: \", type(att_unet_v4_model))\n",
    "\n",
    "# print model summary if you want to\n",
    "print(att_unet_v4_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all modalities and segmentation groundtruth masks for one case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: 240x240\n",
      "Number of slices: 155\n"
     ]
    }
   ],
   "source": [
    "# define path\n",
    "base_path = '../data/BRaTS2021/BRaTS2021_raw/' \n",
    "\n",
    "Flair       = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_flair.nii.gz').get_fdata()\n",
    "seg_target  = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_seg.nii.gz').get_fdata()\n",
    "T1          = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_t1.nii.gz').get_fdata()\n",
    "T1ce        = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_t1ce.nii.gz').get_fdata()\n",
    "T2          = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_t2.nii.gz').get_fdata()\n",
    "\n",
    "# convert from 0, 1, 2, 4 --> 0, 1, 2, 3\n",
    "seg_target[seg_target == 4] = 3  \n",
    "\n",
    "# print number of slices\n",
    "imgshape = Flair.shape\n",
    "print(f\"Image resolution: {imgshape[0]}x{imgshape[1]}\")\n",
    "print(f\"Number of slices: {imgshape[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create transformations for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations.transformations import brats_validation_transform\n",
    "\n",
    "brats_transform = brats_validation_transform(image_keys=['t1', 't1ce', 't2', 'flair'], \n",
    "                                             all_keys=['t1', 't1ce', 't2', 'flair', 'seg'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the specific case we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRI modalities\n",
    "modalities = ['t1', 't1ce', 't2', 'flair'] \n",
    "\n",
    "# placeholders \n",
    "slice_dict = {}\n",
    "\n",
    "# loop over all 155 slices\n",
    "for slice_id in range(155):\n",
    "    # create dictionary for each slice\n",
    "    slice_dict[slice_id] = {}\n",
    "\n",
    "    # get all 4 modalities\n",
    "    t1 = T1[:, :, slice_id]\n",
    "    t1ce = T1ce[:, :, slice_id]\n",
    "    t2 = T2[:, :, slice_id]\n",
    "    flair = Flair[:, :, slice_id]\n",
    "    seg_tar = seg_target[:, :, slice_id]\n",
    "\n",
    "    # create dictionary for each slice \n",
    "    slice_dict[slice_id]['t1'] = t1\n",
    "    slice_dict[slice_id]['t1ce'] = t1ce\n",
    "    slice_dict[slice_id]['t2'] = t2\n",
    "    slice_dict[slice_id]['flair'] = flair\n",
    "    slice_dict[slice_id]['seg'] = seg_tar\n",
    "\n",
    "    # apply transformations\n",
    "    slice_dict[slice_id] = brats_transform(slice_dict[slice_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the loaded case to get the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "att_unet_v4_model.to(device)\n",
    "att_unet_v4_model.eval()\n",
    "\n",
    "seg_preds = []\n",
    "att_coeff1_list = []\n",
    "\n",
    "n_cases = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    for slice_idx in range(155):\n",
    "        modality_dict = slice_dict[slice_idx]\n",
    "\n",
    "        x = torch.cat((modality_dict['flair'], \n",
    "                       modality_dict['t1'], \n",
    "                       modality_dict['t1ce'], \n",
    "                       modality_dict['t2']), dim=0)\n",
    "\n",
    "        # add batch dimension 1\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        # inference\n",
    "        x = x.to(device)\n",
    "        out, att_coeff1, att_coeff2, att_coeff3, att_coeff4 = att_unet_v4_model(x)\n",
    "        seg_preds.append(out)\n",
    "        att_coeff1_list.append(att_coeff1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack them into shape (155, 4, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([155, 4, 240, 240])\n",
      "torch.Size([155, 1, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "# select case\n",
    "start_slice = 0\n",
    "end_slice = 155\n",
    "\n",
    "pred = torch.vstack(seg_preds)\n",
    "pred = pred[start_slice:end_slice].cpu()\n",
    "print(np.shape(pred))\n",
    "att_coeff_out = torch.vstack(att_coeff1_list)\n",
    "att_coeff_out = att_coeff_out[start_slice:end_slice].cpu()\n",
    "print(np.shape(att_coeff_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detach from GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155)\n",
      "(155, 1, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "#seg_output = pred.cpu().detach().numpy()\n",
    "seg_output = pred\n",
    "seg_output = torch.argmax(seg_output, dim=1)\n",
    "seg_output = torch.transpose(seg_output, 0, 2)\n",
    "seg_output = seg_output.cpu().detach().numpy()\n",
    "print (seg_output.shape)\n",
    "\n",
    "att_coeff_out_last = att_coeff_out\n",
    "att_coeff_out_last = torch.argmax(att_coeff_out_last,dim=1)\n",
    "att_coeff_out_last = torch.transpose(att_coeff_out_last, 0, 2)\n",
    "att_coeff_out_last = att_coeff_out.cpu().detach().numpy()\n",
    "print (att_coeff_out_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize segmentation prediction vs groundtruth (overlay on top of Flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0943bb1235ab49b2864090256a956b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=77, description='layer', max=154), Output()), _dom_classes=('widget-inteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize_3d_labels(layer)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict = {\n",
    "    0 : 'B/W = healthy',\n",
    "    1 : 'Red = necrotic',\n",
    "    2 : 'Green = edematous',\n",
    "    3 : 'Blue = enhancing'\n",
    "}\n",
    "print(np.shape(seg_target))\n",
    "\n",
    "# change colours of segmentation result  \n",
    "color_segmentation = np.zeros((240, 240, 155, 3), dtype=np.uint8)\n",
    "color_segmentation_pred = np.zeros((240, 240, 155, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "# replace 4 with 3\n",
    "seg_target[seg_target == 4] = 3\n",
    "                                                     # Black (healthy tissue) = 0\n",
    "color_segmentation[seg_target == 1] = [255, 0, 0]    # Red (necrotic tumor core) = 1\n",
    "color_segmentation[seg_target == 2] = [0, 255, 0]    # Green (peritumoral edematous/invaded tissue) = 2\n",
    "color_segmentation[seg_target == 3] = [0, 0, 255]    # Blue (enhancing tumor) = 4\n",
    "\n",
    "def create_seg_figure(background, color_seg, att_coeff_out_last, slice_idx):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    att_coeff_out_last = -1*(att_coeff_out_last - 1)\n",
    "\n",
    "    # prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(background, cmap='bone')\n",
    "    plt.imshow(att_coeff_out_last, cmap='jet', alpha=0.6)\n",
    "    plt.title(\"prediction\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar(fraction=0.046, pad=0.01, cmap='jet')\n",
    "\n",
    "    # case and slice id\n",
    "    subtext = f\"BRaTS2021_{sample_id}\"\n",
    "    slice_txt = f\"{slice_idx:03d}\"\n",
    "    plt.text(45, 230, subtext, fontsize=20, color='white')\n",
    "    plt.text(10, 30, slice_txt, fontsize=30, color='white')\n",
    "    \n",
    "    # target\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(background, cmap='gray')\n",
    "    plt.imshow(color_seg, cmap='bone', alpha=0.6)\n",
    "    plt.title(\"target\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.text(45, 230, subtext, fontsize=20, color='white')\n",
    "    plt.text(10, 30, slice_txt, fontsize=30, color='white')\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "def visualize_3d_labels(layer):\n",
    "    color_seg = color_segmentation[:, :, layer, :]\n",
    "    color_seg_pred = att_coeff_out_last[layer,0,:,:]#[:, :, layer, :]\n",
    "\n",
    "    # print segmentation result\n",
    "    print([classes_dict[int(result)] for result in np.unique(seg_target[:, :, layer])])\n",
    " \n",
    "    background = Flair[:, :, layer]\n",
    "    plot = create_seg_figure(background, color_seg, color_seg_pred, layer)\n",
    "    plot.show()\n",
    "\n",
    "    return layer\n",
    "\n",
    "interact(visualize_3d_labels, layer=(0, Flair.shape[2] - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d682f74c9ad418ca1e971b83eab4888a7eba299d9a86b811e07ae143a3b11ff5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
