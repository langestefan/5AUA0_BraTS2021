{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import gzip\n",
    "import os\n",
    "import cv2\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import sys\n",
    "\n",
    "# for relative imports to work in notebooks\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from model.model  import BraTS2021BaseUnetModel, BraTS2021AttentionUnetModel_V4\n",
    "\n",
    "from monai.metrics import compute_generalized_dice, compute_meandice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select which BRaTS2021 case we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = '00349'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of model:  <class 'model.model.BraTS2021AttentionUnetModel_V4'>\n",
      "BraTS2021AttentionUnetModel_V4(\n",
      "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv1): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv2): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv3): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv4): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv5): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up5): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att5): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv5): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up4): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att4): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv4): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up3): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att3): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv3): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Up2): up_conv(\n",
      "    (up): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Att2): Attention_block_V4(\n",
      "    (W_g): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (W_x): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (psi): Sequential(\n",
      "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (Up_conv2): conv_block(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (Conv_1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model is located at: \n",
    "unet_base_model_path = '../saved/models/base_unet_dice/model_best.pth'\n",
    "unet_base_aug_model_path = '../saved/models/BraTS2021_Base_Unet/0616_220253/model_best.pth'\n",
    "unet_attention_model_path = '../saved/models/attention_unet_dice_v4/model_best.pth'\n",
    "\n",
    "\n",
    "model_path = unet_attention_model_path\n",
    "\n",
    "# load base unet model\n",
    "# model = BraTS2021BaseUnetModel()\n",
    "model = BraTS2021AttentionUnetModel_V4()\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "state_dict = checkpoint['state_dict']\n",
    "# base_unet_model.load_state_dict(state_dict)\n",
    "model.load_state_dict(state_dict)\n",
    "print(\"type of model: \", type(model))\n",
    "\n",
    "# print model summary if you want to\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all modalities and segmentation groundtruth masks for one case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resolution: 240x240\n",
      "Number of slices: 155\n"
     ]
    }
   ],
   "source": [
    "# define path\n",
    "base_path = '../data/BRaTS2021/BRaTS2021_raw/' \n",
    "\n",
    "Flair       = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_flair.nii.gz').get_fdata()\n",
    "seg_target  = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_seg.nii.gz').get_fdata()\n",
    "T1          = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_t1.nii.gz').get_fdata()\n",
    "T1ce        = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_t1ce.nii.gz').get_fdata()\n",
    "T2          = nib.load(base_path  + 'BraTS2021_' + sample_id  + '/BraTS2021_' + sample_id + '_t2.nii.gz').get_fdata()\n",
    "\n",
    "# convert from 0, 1, 2, 4 --> 0, 1, 2, 3\n",
    "seg_target[seg_target == 4] = 3  \n",
    "\n",
    "# print number of slices\n",
    "imgshape = Flair.shape\n",
    "print(f\"Image resolution: {imgshape[0]}x{imgshape[1]}\")\n",
    "print(f\"Number of slices: {imgshape[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create transformations for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations.transformations import brats_validation_transform\n",
    "\n",
    "brats_transform = brats_validation_transform(image_keys=['t1', 't1ce', 't2', 'flair'], \n",
    "                                             all_keys=['t1', 't1ce', 't2', 'flair', 'seg'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the specific case we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRI modalities\n",
    "modalities = ['t1', 't1ce', 't2', 'flair'] \n",
    "\n",
    "# placeholders \n",
    "slice_dict = {}\n",
    "\n",
    "# loop over all 155 slices\n",
    "for slice_id in range(155):\n",
    "    # create dictionary for each slice\n",
    "    slice_dict[slice_id] = {}\n",
    "\n",
    "    # get all 4 modalities\n",
    "    t1 = T1[:, :, slice_id]\n",
    "    t1ce = T1ce[:, :, slice_id]\n",
    "    t2 = T2[:, :, slice_id]\n",
    "    flair = Flair[:, :, slice_id]\n",
    "    seg_tar = seg_target[:, :, slice_id]\n",
    "\n",
    "    # create dictionary for each slice \n",
    "    slice_dict[slice_id]['t1'] = t1\n",
    "    slice_dict[slice_id]['t1ce'] = t1ce\n",
    "    slice_dict[slice_id]['t2'] = t2\n",
    "    slice_dict[slice_id]['flair'] = flair\n",
    "    slice_dict[slice_id]['seg'] = seg_tar\n",
    "\n",
    "    # apply transformations\n",
    "    slice_dict[slice_id] = brats_transform(slice_dict[slice_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the loaded case to get the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "seg_preds = []\n",
    "\n",
    "n_cases = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    for slice_idx in range(155):\n",
    "        modality_dict = slice_dict[slice_idx]\n",
    "\n",
    "        x = torch.cat((modality_dict['flair'], \n",
    "                       modality_dict['t1'], \n",
    "                       modality_dict['t1ce'], \n",
    "                       modality_dict['t2']), dim=0)\n",
    "\n",
    "        # add batch dimension 1\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        # inference\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        seg_preds.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack them into shape (155, 4, 240, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([155, 4, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "# select case\n",
    "start_slice = 0\n",
    "end_slice = 155\n",
    "\n",
    "pred = torch.vstack(seg_preds)\n",
    "pred = pred[start_slice:end_slice].cpu()\n",
    "print(np.shape(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detach from GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155)\n"
     ]
    }
   ],
   "source": [
    "#seg_output = pred.cpu().detach().numpy()\n",
    "seg_output = pred\n",
    "seg_output = torch.argmax(seg_output, dim=1)\n",
    "seg_output = torch.transpose(seg_output, 0, 2)\n",
    "seg_output = seg_output.cpu().detach().numpy()\n",
    "print (seg_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize segmentation prediction vs groundtruth (overlay on top of Flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f44fa6969004b3d849a135857f816d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=77, description='layer', max=154), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize_3d_labels(layer)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict = {\n",
    "    0 : 'B/W = healthy',\n",
    "    1 : 'Red = necrotic',\n",
    "    2 : 'Green = edematous',\n",
    "    3 : 'Blue = enhancing'\n",
    "}\n",
    "print(np.shape(seg_target))\n",
    "\n",
    "# change colours of segmentation result  \n",
    "color_segmentation = np.zeros((240, 240, 155, 3), dtype=np.uint8)\n",
    "color_segmentation_pred = np.zeros((240, 240, 155, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "# replace 4 with 3\n",
    "seg_target[seg_target == 4] = 3\n",
    "                                                            # Black (healthy tissue) = 0\n",
    "color_segmentation[seg_target == 1] = [255, 0, 0]    # Red (necrotic tumor core) = 1\n",
    "color_segmentation[seg_target == 2] = [0, 255, 0]    # Green (peritumoral edematous/invaded tissue) = 2\n",
    "color_segmentation[seg_target == 3] = [0, 0, 255]    # Blue (enhancing tumor) = 4\n",
    "\n",
    "                                                                    # Black (healthy tissue) = 0\n",
    "color_segmentation_pred[seg_output == 1] = [255, 0, 0]  # Red (necrotic tumor core) = 1\n",
    "color_segmentation_pred[seg_output == 2] = [0, 255, 0]  # Green (peritumoral edematous/invaded tissue) = 2\n",
    "color_segmentation_pred[seg_output == 3] = [0, 0, 255]  # Blue (enhancing tumor) = 4\n",
    "\n",
    "\n",
    "def create_seg_figure(background, color_seg, color_seg_pred, slice_idx):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(background, cmap='gray')\n",
    "    plt.imshow(color_seg_pred, cmap='bone', alpha=0.6)\n",
    "    plt.title(\"prediction\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # case and slice id\n",
    "    subtext = f\"BRaTS2021_{sample_id}\"\n",
    "    slice_txt = f\"{slice_idx:03d}\"\n",
    "    plt.text(45, 230, subtext, fontsize=20, color='white')\n",
    "    plt.text(10, 30, slice_txt, fontsize=30, color='white')\n",
    "    \n",
    "    # target\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(background, cmap='gray')\n",
    "    plt.imshow(color_seg, cmap='bone', alpha=0.6)\n",
    "    plt.title(\"target\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.text(45, 230, subtext, fontsize=20, color='white')\n",
    "    plt.text(10, 30, slice_txt, fontsize=30, color='white')\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "def visualize_3d_labels(layer):\n",
    "    color_seg = color_segmentation[:, :, layer, :]\n",
    "    color_seg_pred = color_segmentation_pred[:, :, layer, :]\n",
    "\n",
    "    # print segmentation result\n",
    "    print([classes_dict[int(result)] for result in np.unique(seg_target[:, :, layer])])\n",
    " \n",
    "    background = Flair[:, :, layer]\n",
    "    plot = create_seg_figure(background, color_seg, color_seg_pred, layer)\n",
    "    plot.show()\n",
    "\n",
    "    return layer\n",
    "\n",
    "interact(visualize_3d_labels, layer=(0, Flair.shape[2] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create WT, TC, ET masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_tumor_mask(output, target):\n",
    "    \"\"\" Dice coeffecient for whole tumor (union of classes 1-3)\n",
    "        See: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook#Dice-Loss\n",
    "    Args:\n",
    "        output (torch.Tensor): model output probalities between [0-1], shape (N, C, H, W)\n",
    "        target (torch.Tensor): target one-hot encoded, shape (N, C, H, W)\n",
    "        eps (int): prevent division by 0\n",
    "    Returns:\n",
    "        torch.Tensor: dice coeff. Shape: (1,)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        print(\"output shape: \", output.shape)\n",
    "        print(\"target shape: \", target.shape)\n",
    "\n",
    "        # for the target we want to take the union of all the tumor classes\n",
    "        # target_union = torch.sum(target[:, 1:], dim=1).clip(0, 1).unsqueeze(1).cpu()\n",
    "        # print(\"target_union\", target_union)\n",
    "        target_union = target.clip(0, 1).cpu()\n",
    "\n",
    "        # for the output we want to take the argmax of all the classes\n",
    "        # output_union = torch.argmax(output, dim=1).clip(0, 1).unsqueeze(1).cpu()\n",
    "        # print(\"output_union \", output_union)\n",
    "        output_union = output.clip(0, 1).cpu()\n",
    "\n",
    "    return output_union, target_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([240, 240, 155])\n",
      "target shape:  torch.Size([240, 240, 155])\n",
      "wt_out:  torch.Size([240, 240, 155])\n",
      "wt_target:  torch.Size([240, 240, 155])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecfbe8aef3b41dbb682caad0da957d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=77, description='layer', max=154), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize_masks(layer)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(seg_target.shape)\n",
    "\n",
    "wt_out, wt_target = whole_tumor_mask(torch.from_numpy(seg_output), torch.from_numpy(seg_target))\n",
    "\n",
    "print(\"wt_out: \", wt_out.shape)\n",
    "print(\"wt_target: \", wt_target.shape)\n",
    "\n",
    "def visualize_masks(layer):\n",
    "    color_seg_wt = wt_target[:, :, layer]\n",
    "    color_seg_pred_wt = wt_out[:, :, layer]\n",
    "    print(color_seg_wt.shape)\n",
    "    print(color_seg_pred_wt.shape)\n",
    "\n",
    "    # print segmentation result\n",
    "    print([classes_dict[int(result)] for result in np.unique(seg_target[:, :, layer])])\n",
    " \n",
    "    background = Flair[:, :, layer]\n",
    "    plot = create_seg_figure(background, color_seg_wt, color_seg_pred_wt, layer)\n",
    "    plot.show()\n",
    "\n",
    "    return layer\n",
    "\n",
    "interact(visualize_masks, layer=(0, Flair.shape[2] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute dice coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt_out:  torch.Size([155, 240, 240])\n",
      "wt_target:  torch.Size([155, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "from monai.metrics import compute_generalized_dice, compute_meandice\n",
    "\n",
    "wt_out = torch.transpose(wt_out, 0, 2)\n",
    "print(\"wt_out: \", wt_out.shape)\n",
    "wt_target = torch.transpose(wt_target, 0, 2)\n",
    "print(\"wt_target: \", wt_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt_out:  torch.Size([155, 240, 240])\n",
      "wt_target:  torch.Size([155, 240, 240])\n",
      "min_slice:max_slice = 32:90\n",
      "wt_out_sliced:  torch.Size([59, 240, 240])\n",
      "wt_target_sliced:  torch.Size([59, 240, 240])\n",
      "wt_out_sliced:  torch.Size([1, 1, 59, 240, 240])\n",
      "wt_target_sliced:  torch.Size([1, 1, 59, 240, 240])\n",
      "dice_score_wt:  tensor(0.6678)\n"
     ]
    }
   ],
   "source": [
    "wt_out_orig = wt_out.clone()\n",
    "wt_target_orig = wt_target.clone()\n",
    "\n",
    "# remove all slices with no tumor\n",
    "print(\"wt_out: \", wt_out.shape)\n",
    "print(\"wt_target: \", wt_target.shape)\n",
    "\n",
    "# take only slices that have tumor in prediction or target\n",
    "wt_out_indices = torch.where(wt_out.sum(dim=(1,2)) > 0)\n",
    "wt_target_indices = torch.where(wt_target.sum(dim=(1,2)) > 0)\n",
    "\n",
    "min_slice = min(wt_out_indices[0].min(), wt_target_indices[0].min())\n",
    "max_slice = max(wt_out_indices[0].max(), wt_target_indices[0].max())\n",
    "\n",
    "print(\"min_slice:max_slice = {}:{}\".format(min_slice, max_slice))\n",
    "\n",
    "# remove all slices with no tumor\n",
    "wt_out_sliced = wt_out[min_slice:max_slice + 1]\n",
    "wt_target_sliced = wt_target[min_slice:max_slice + 1]\n",
    "\n",
    "print(\"wt_out_sliced: \", wt_out_sliced.shape)\n",
    "print(\"wt_target_sliced: \", wt_target_sliced.shape)\n",
    "\n",
    "# unsqueeze two times, one for batchsize=1 and one for channel=1\n",
    "wt_out_sliced = wt_out_sliced.unsqueeze(0).unsqueeze(0)\n",
    "wt_target_sliced = wt_target_sliced.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(\"wt_out_sliced: \", wt_out_sliced.shape)\n",
    "print(\"wt_target_sliced: \", wt_target_sliced.shape)\n",
    "\n",
    "dice_score_wt = torch.as_tensor(compute_meandice(wt_out_sliced, wt_target_sliced))\n",
    "\n",
    "# print(\"dice_score_wt shape: \", dice_score_wt.shape)\n",
    "print(\"dice_score_wt: \", torch.mean(dice_score_wt))\n",
    "# print(\"dice_score_wt: \", dice_score_wt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369441202de9f090a0e57b38848d3e186c8686d751df00b39c544f960532016f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
